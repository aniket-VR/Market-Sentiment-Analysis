{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pytz\n",
    "\n",
    "from modules.data_fetcher import download_historical_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch historical price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1153, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 01:00:00</th>\n",
       "      <td>1.577837e+09</td>\n",
       "      <td>7196.2</td>\n",
       "      <td>7200.2</td>\n",
       "      <td>7251.8</td>\n",
       "      <td>7176.1</td>\n",
       "      <td>370.594061</td>\n",
       "      <td>2.675032e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 01:00:00</th>\n",
       "      <td>1.577923e+09</td>\n",
       "      <td>7200.3</td>\n",
       "      <td>6964.8</td>\n",
       "      <td>7210.6</td>\n",
       "      <td>6933.3</td>\n",
       "      <td>834.203799</td>\n",
       "      <td>5.900888e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 01:00:00</th>\n",
       "      <td>1.578010e+09</td>\n",
       "      <td>6964.8</td>\n",
       "      <td>7346.2</td>\n",
       "      <td>7397.7</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1325.683236</td>\n",
       "      <td>9.586604e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 01:00:00</th>\n",
       "      <td>1.578096e+09</td>\n",
       "      <td>7344.6</td>\n",
       "      <td>7355.3</td>\n",
       "      <td>7399.0</td>\n",
       "      <td>7271.5</td>\n",
       "      <td>695.820296</td>\n",
       "      <td>5.098636e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05 01:00:00</th>\n",
       "      <td>1.578182e+09</td>\n",
       "      <td>7355.9</td>\n",
       "      <td>7359.9</td>\n",
       "      <td>7490.0</td>\n",
       "      <td>7320.7</td>\n",
       "      <td>948.491582</td>\n",
       "      <td>7.052092e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Timestamp    Open   Close    High     Low  \\\n",
       "Date                                                                \n",
       "2020-01-01 01:00:00  1.577837e+09  7196.2  7200.2  7251.8  7176.1   \n",
       "2020-01-02 01:00:00  1.577923e+09  7200.3  6964.8  7210.6  6933.3   \n",
       "2020-01-03 01:00:00  1.578010e+09  6964.8  7346.2  7397.7  6867.0   \n",
       "2020-01-04 01:00:00  1.578096e+09  7344.6  7355.3  7399.0  7271.5   \n",
       "2020-01-05 01:00:00  1.578182e+09  7355.9  7359.9  7490.0  7320.7   \n",
       "\n",
       "                          Amount        Volume  \n",
       "Date                                            \n",
       "2020-01-01 01:00:00   370.594061  2.675032e+06  \n",
       "2020-01-02 01:00:00   834.203799  5.900888e+06  \n",
       "2020-01-03 01:00:00  1325.683236  9.586604e+06  \n",
       "2020-01-04 01:00:00   695.820296  5.098636e+06  \n",
       "2020-01-05 01:00:00   948.491582  7.052092e+06  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_df = download_historical_data('BTC-USDT','1day').loc[\"2020-01-01\":]\n",
    "print(btc_df.shape)\n",
    "btc_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fecth google trends price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function, unicode_literals\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from pandas.io.json._normalize import nested_to_record\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "from urllib.parse import quote\n",
    "    \n",
    "class ResponseError(Exception):\n",
    "    \"\"\"Something was wrong with the response from Google\"\"\"\n",
    "\n",
    "    def __init__(self, message, response):\n",
    "        super(Exception, self).__init__(message)\n",
    "\n",
    "        # pass response so it can be handled upstream\n",
    "        self.response = response\n",
    "\n",
    "\n",
    "\n",
    "class GTrends(object):\n",
    "    \"\"\"\n",
    "    Google Trends API\n",
    "    \"\"\"\n",
    "    GET_METHOD = 'get'\n",
    "    POST_METHOD = 'post'\n",
    "    GENERAL_URL = 'https://trends.google.com/trends/api/explore'\n",
    "    INTEREST_OVER_TIME_URL = 'https://trends.google.com/trends/api/widgetdata/multiline'\n",
    "    INTEREST_BY_REGION_URL = 'https://trends.google.com/trends/api/widgetdata/comparedgeo'\n",
    "    RELATED_QUERIES_URL = 'https://trends.google.com/trends/api/widgetdata/relatedsearches'\n",
    "    TRENDING_SEARCHES_URL = 'https://trends.google.com/trends/hottrends/visualize/internal/data'\n",
    "    TOP_CHARTS_URL = 'https://trends.google.com/trends/api/topcharts'\n",
    "    SUGGESTIONS_URL = 'https://trends.google.com/trends/api/autocomplete/'\n",
    "    CATEGORIES_URL = 'https://trends.google.com/trends/api/explore/pickers/category'\n",
    "    TODAY_SEARCHES_URL = 'https://trends.google.com/trends/api/dailytrends'\n",
    "\n",
    "    def __init__(self, hl='en-US', tz=360, geo='', timeout=(2, 5), proxies='',\n",
    "                 retries=0, backoff_factor=0):\n",
    "        \"\"\"\n",
    "        Initialize default values for params\n",
    "        \"\"\"\n",
    "        # google rate limit\n",
    "        self.google_rl = 'You have reached your quota limit. Please try again later.'\n",
    "        self.results = None\n",
    "        # set user defined options used globally\n",
    "        self.tz = tz\n",
    "        self.hl = hl\n",
    "        self.geo = geo\n",
    "        self.kw_list = list()\n",
    "        self.timeout = timeout\n",
    "        self.proxies = proxies  # add a proxy option\n",
    "        self.retries = retries\n",
    "        self.backoff_factor = backoff_factor\n",
    "        self.proxy_index = 0\n",
    "        self.cookies = self.GetGoogleCookie()\n",
    "        # intialize widget payloads\n",
    "        self.token_payload = dict()\n",
    "        self.interest_over_time_widget = dict()\n",
    "        self.interest_by_region_widget = dict()\n",
    "        self.related_topics_widget_list = list()\n",
    "        self.related_queries_widget_list = list()\n",
    "\n",
    "    def GetGoogleCookie(self):\n",
    "        \"\"\"\n",
    "        Gets google cookie (used for each and every proxy; once on init otherwise)\n",
    "        Removes proxy from the list on proxy error\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            if len(self.proxies) > 0:\n",
    "                proxy = {'https': self.proxies[self.proxy_index]}\n",
    "            else:\n",
    "                proxy = ''\n",
    "            try:\n",
    "                return dict(filter(lambda i: i[0] == 'NID', requests.get(\n",
    "                    'https://trends.google.com/?geo={geo}'.format(\n",
    "                        geo=self.hl[-2:]),\n",
    "                    timeout=self.timeout,\n",
    "                    proxies=proxy\n",
    "                ).cookies.items()))\n",
    "            except requests.exceptions.ProxyError:\n",
    "                print('Proxy error. Changing IP')\n",
    "                if len(self.proxies) > 0:\n",
    "                    self.proxies.remove(self.proxies[self.proxy_index])\n",
    "                else:\n",
    "                    print('Proxy list is empty. Bye!')\n",
    "                continue\n",
    "\n",
    "    def GetNewProxy(self):\n",
    "        \"\"\"\n",
    "        Increment proxy INDEX; zero on overflow\n",
    "        \"\"\"\n",
    "        if self.proxy_index < (len(self.proxies) - 1):\n",
    "            self.proxy_index += 1\n",
    "        else:\n",
    "            self.proxy_index = 0\n",
    "\n",
    "    def _get_data(self, url, method=GET_METHOD, trim_chars=0, **kwargs):\n",
    "        \"\"\"Send a request to Google and return the JSON response as a Python object\n",
    "        :param url: the url to which the request will be sent\n",
    "        :param method: the HTTP method ('get' or 'post')\n",
    "        :param trim_chars: how many characters should be trimmed off the beginning of the content of the response\n",
    "            before this is passed to the JSON parser\n",
    "        :param kwargs: any extra key arguments passed to the request builder (usually query parameters or data)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        s = requests.session()\n",
    "        # Retries mechanism. Activated when one of statements >0 (best used for proxy)\n",
    "        if self.retries > 0 or self.backoff_factor > 0:\n",
    "            retry = Retry(total=self.retries, read=self.retries,\n",
    "                          connect=self.retries,\n",
    "                          backoff_factor=self.backoff_factor)\n",
    "            adapter = HTTPAdapter(max_retries=retry)\n",
    "        s.headers.update({'accept-language': self.hl})\n",
    "        if len(self.proxies) > 0:\n",
    "            self.cookies = self.GetGoogleCookie()\n",
    "            s.proxies.update({'https': self.proxies[self.proxy_index]})\n",
    "        if method == TrendReq.POST_METHOD:\n",
    "            response = s.post(url, timeout=self.timeout,\n",
    "                              cookies=self.cookies, **kwargs)  # DO NOT USE retries or backoff_factor here\n",
    "        else:\n",
    "            response = s.get(url, timeout=self.timeout, cookies=self.cookies,\n",
    "                             **kwargs)  # DO NOT USE retries or backoff_factor here\n",
    "        # check if the response contains json and throw an exception otherwise\n",
    "        # Google mostly sends 'application/json' in the Content-Type header,\n",
    "        # but occasionally it sends 'application/javascript\n",
    "        # and sometimes even 'text/javascript\n",
    "        if response.status_code == 200 and 'application/json' in \\\n",
    "                response.headers['Content-Type'] or \\\n",
    "                'application/javascript' in response.headers['Content-Type'] or \\\n",
    "                'text/javascript' in response.headers['Content-Type']:\n",
    "            # trim initial characters\n",
    "            # some responses start with garbage characters, like \")]}',\"\n",
    "            # these have to be cleaned before being passed to the json parser\n",
    "            content = response.text[trim_chars:]\n",
    "            # parse json\n",
    "            self.GetNewProxy()\n",
    "            return json.loads(content)\n",
    "        else:\n",
    "            # error\n",
    "            raise ResponseError(\n",
    "                'The request failed: Google returned a '\n",
    "                'response with code {0}.'.format(response.status_code),\n",
    "                response=response)\n",
    "\n",
    "    def build_payload(self, kw_list, cat=0, timeframe='today 5-y', geo='',\n",
    "                      gprop=''):\n",
    "        \"\"\"Create the payload for related queries, interest over time and interest by region\"\"\"\n",
    "        self.kw_list = kw_list\n",
    "        self.geo = geo or self.geo\n",
    "        self.token_payload = {\n",
    "            'hl': self.hl,\n",
    "            'tz': self.tz,\n",
    "            'req': {'comparisonItem': [], 'category': cat, 'property': gprop}\n",
    "        }\n",
    "\n",
    "        # build out json for each keyword\n",
    "        for kw in self.kw_list:\n",
    "            keyword_payload = {'keyword': kw, 'time': timeframe,\n",
    "                               'geo': self.geo}\n",
    "            self.token_payload['req']['comparisonItem'].append(keyword_payload)\n",
    "        # requests will mangle this if it is not a string\n",
    "        self.token_payload['req'] = json.dumps(self.token_payload['req'])\n",
    "        # get tokens\n",
    "        self._tokens()\n",
    "        return\n",
    "\n",
    "    def _tokens(self):\n",
    "        \"\"\"Makes request to Google to get API tokens for interest over time, interest by region and related queries\"\"\"\n",
    "        # make the request and parse the returned json\n",
    "        widget_dict = self._get_data(\n",
    "            url=TrendReq.GENERAL_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            params=self.token_payload,\n",
    "            trim_chars=4,\n",
    "        )['widgets']\n",
    "        # order of the json matters...\n",
    "        first_region_token = True\n",
    "        # clear self.related_queries_widget_list and self.related_topics_widget_list\n",
    "        # of old keywords'widgets\n",
    "        self.related_queries_widget_list[:] = []\n",
    "        self.related_topics_widget_list[:] = []\n",
    "        # assign requests\n",
    "        for widget in widget_dict:\n",
    "            if widget['id'] == 'TIMESERIES':\n",
    "                self.interest_over_time_widget = widget\n",
    "            if widget['id'] == 'GEO_MAP' and first_region_token:\n",
    "                self.interest_by_region_widget = widget\n",
    "                first_region_token = False\n",
    "            # response for each term, put into a list\n",
    "            if 'RELATED_TOPICS' in widget['id']:\n",
    "                self.related_topics_widget_list.append(widget)\n",
    "            if 'RELATED_QUERIES' in widget['id']:\n",
    "                self.related_queries_widget_list.append(widget)\n",
    "        return\n",
    "\n",
    "    def interest_over_time(self):\n",
    "        \"\"\"Request data from Google's Interest Over Time section and return a dataframe\"\"\"\n",
    "\n",
    "        over_time_payload = {\n",
    "            # convert to string as requests will mangle\n",
    "            'req': json.dumps(self.interest_over_time_widget['request']),\n",
    "            'token': self.interest_over_time_widget['token'],\n",
    "            'tz': self.tz\n",
    "        }\n",
    "\n",
    "        # make the request and parse the returned json\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.INTEREST_OVER_TIME_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "            params=over_time_payload,\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame(req_json['default']['timelineData'])\n",
    "        if (df.empty):\n",
    "            return df\n",
    "\n",
    "        df['date'] = pd.to_datetime(df['time'].astype(dtype='float64'),\n",
    "                                    unit='s')\n",
    "        df = df.set_index(['date']).sort_index()\n",
    "        # split list columns into seperate ones, remove brackets and split on comma\n",
    "        result_df = df['value'].apply(lambda x: pd.Series(\n",
    "            str(x).replace('[', '').replace(']', '').split(',')))\n",
    "        # rename each column with its search term, relying on order that google provides...\n",
    "        for idx, kw in enumerate(self.kw_list):\n",
    "            # there is currently a bug with assigning columns that may be\n",
    "            # parsed as a date in pandas: use explicit insert column method\n",
    "            result_df.insert(len(result_df.columns), kw,\n",
    "                             result_df[idx].astype('int'))\n",
    "            del result_df[idx]\n",
    "\n",
    "        if 'isPartial' in df:\n",
    "            # make other dataframe from isPartial key data\n",
    "            # split list columns into seperate ones, remove brackets and split on comma\n",
    "            df = df.fillna(False)\n",
    "            result_df2 = df['isPartial'].apply(lambda x: pd.Series(\n",
    "                str(x).replace('[', '').replace(']', '').split(',')))\n",
    "            result_df2.columns = ['isPartial']\n",
    "            # concatenate the two dataframes\n",
    "            final = pd.concat([result_df, result_df2], axis=1)\n",
    "        else:\n",
    "            final = result_df\n",
    "            final['isPartial'] = False\n",
    "\n",
    "        return final\n",
    "\n",
    "    def interest_by_region(self, resolution='COUNTRY', inc_low_vol=False,\n",
    "                           inc_geo_code=False):\n",
    "        \"\"\"Request data from Google's Interest by Region section and return a dataframe\"\"\"\n",
    "\n",
    "        # make the request\n",
    "        region_payload = dict()\n",
    "        if self.geo == '':\n",
    "            self.interest_by_region_widget['request'][\n",
    "                'resolution'] = resolution\n",
    "        elif self.geo == 'US' and resolution in ['DMA', 'CITY', 'REGION']:\n",
    "            self.interest_by_region_widget['request'][\n",
    "                'resolution'] = resolution\n",
    "\n",
    "        self.interest_by_region_widget['request'][\n",
    "            'includeLowSearchVolumeGeos'] = inc_low_vol\n",
    "\n",
    "        # convert to string as requests will mangle\n",
    "        region_payload['req'] = json.dumps(\n",
    "            self.interest_by_region_widget['request'])\n",
    "        region_payload['token'] = self.interest_by_region_widget['token']\n",
    "        region_payload['tz'] = self.tz\n",
    "\n",
    "        # parse returned json\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.INTEREST_BY_REGION_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "            params=region_payload,\n",
    "        )\n",
    "        df = pd.DataFrame(req_json['default']['geoMapData'])\n",
    "        if (df.empty):\n",
    "            return df\n",
    "\n",
    "        # rename the column with the search keyword\n",
    "        df = df[['geoName', 'geoCode', 'value']].set_index(\n",
    "            ['geoName']).sort_index()\n",
    "        # split list columns into seperate ones, remove brackets and split on comma\n",
    "        result_df = df['value'].apply(lambda x: pd.Series(\n",
    "            str(x).replace('[', '').replace(']', '').split(',')))\n",
    "        if inc_geo_code:\n",
    "            result_df['geoCode'] = df['geoCode']\n",
    "\n",
    "        # rename each column with its search term\n",
    "        for idx, kw in enumerate(self.kw_list):\n",
    "            result_df[kw] = result_df[idx].astype('int')\n",
    "            del result_df[idx]\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def related_topics(self):\n",
    "        \"\"\"Request data from Google's Related Topics section and return a dictionary of dataframes\n",
    "\n",
    "        If no top and/or rising related topics are found, the value for the key \"top\" and/or \"rising\" will be None\n",
    "        \"\"\"\n",
    "\n",
    "        # make the request\n",
    "        related_payload = dict()\n",
    "        result_dict = dict()\n",
    "        for request_json in self.related_topics_widget_list:\n",
    "            # ensure we know which keyword we are looking at rather than relying on order\n",
    "            kw = request_json['request']['restriction'][\n",
    "                'complexKeywordsRestriction']['keyword'][0]['value']\n",
    "            # convert to string as requests will mangle\n",
    "            related_payload['req'] = json.dumps(request_json['request'])\n",
    "            related_payload['token'] = request_json['token']\n",
    "            related_payload['tz'] = self.tz\n",
    "\n",
    "            # parse the returned json\n",
    "            req_json = self._get_data(\n",
    "                url=TrendReq.RELATED_QUERIES_URL,\n",
    "                method=TrendReq.GET_METHOD,\n",
    "                trim_chars=5,\n",
    "                params=related_payload,\n",
    "            )\n",
    "\n",
    "            # top topics\n",
    "            try:\n",
    "                top_list = req_json['default']['rankedList'][0][\n",
    "                    'rankedKeyword']\n",
    "                df_top = pd.DataFrame(\n",
    "                    [nested_to_record(d, sep='_') for d in top_list])\n",
    "            except KeyError:\n",
    "                # in case no top topics are found, the lines above will throw a KeyError\n",
    "                df_top = None\n",
    "\n",
    "            # rising topics\n",
    "            try:\n",
    "                rising_list = req_json['default']['rankedList'][1][\n",
    "                    'rankedKeyword']\n",
    "                df_rising = pd.DataFrame(\n",
    "                    [nested_to_record(d, sep='_') for d in rising_list])\n",
    "            except KeyError:\n",
    "                # in case no rising topics are found, the lines above will throw a KeyError\n",
    "                df_rising = None\n",
    "\n",
    "            result_dict[kw] = {'rising': df_rising, 'top': df_top}\n",
    "        return result_dict\n",
    "\n",
    "    def related_queries(self):\n",
    "        \"\"\"Request data from Google's Related Queries section and return a dictionary of dataframes\n",
    "\n",
    "        If no top and/or rising related queries are found, the value for the key \"top\" and/or \"rising\" will be None\n",
    "        \"\"\"\n",
    "\n",
    "        # make the request\n",
    "        related_payload = dict()\n",
    "        result_dict = dict()\n",
    "        for request_json in self.related_queries_widget_list:\n",
    "            # ensure we know which keyword we are looking at rather than relying on order\n",
    "            kw = request_json['request']['restriction'][\n",
    "                'complexKeywordsRestriction']['keyword'][0]['value']\n",
    "            # convert to string as requests will mangle\n",
    "            related_payload['req'] = json.dumps(request_json['request'])\n",
    "            related_payload['token'] = request_json['token']\n",
    "            related_payload['tz'] = self.tz\n",
    "\n",
    "            # parse the returned json\n",
    "            req_json = self._get_data(\n",
    "                url=TrendReq.RELATED_QUERIES_URL,\n",
    "                method=TrendReq.GET_METHOD,\n",
    "                trim_chars=5,\n",
    "                params=related_payload,\n",
    "            )\n",
    "\n",
    "            # top queries\n",
    "            try:\n",
    "                top_df = pd.DataFrame(\n",
    "                    req_json['default']['rankedList'][0]['rankedKeyword'])\n",
    "                top_df = top_df[['query', 'value']]\n",
    "            except KeyError:\n",
    "                # in case no top queries are found, the lines above will throw a KeyError\n",
    "                top_df = None\n",
    "\n",
    "            # rising queries\n",
    "            try:\n",
    "                rising_df = pd.DataFrame(\n",
    "                    req_json['default']['rankedList'][1]['rankedKeyword'])\n",
    "                rising_df = rising_df[['query', 'value']]\n",
    "            except KeyError:\n",
    "                # in case no rising queries are found, the lines above will throw a KeyError\n",
    "                rising_df = None\n",
    "\n",
    "            result_dict[kw] = {'top': top_df, 'rising': rising_df}\n",
    "        return result_dict\n",
    "\n",
    "    def trending_searches(self, pn='united_states'):\n",
    "        \"\"\"Request data from Google's Hot Searches section and return a dataframe\"\"\"\n",
    "\n",
    "        # make the request\n",
    "        # forms become obsolute due to the new TRENDING_SEACHES_URL\n",
    "        # forms = {'ajax': 1, 'pn': pn, 'htd': '', 'htv': 'l'}\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.TRENDING_SEARCHES_URL,\n",
    "            method=TrendReq.GET_METHOD\n",
    "        )[pn]\n",
    "        result_df = pd.DataFrame(req_json)\n",
    "        return result_df\n",
    "\n",
    "    def today_searches(self, pn='US'):\n",
    "        \"\"\"Request data from Google Daily Trends section and returns a dataframe\"\"\"\n",
    "        forms = {'ns': 15, 'geo': pn, 'tz': '-180', 'hl': 'en-US'}\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.TODAY_SEARCHES_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "            params=forms\n",
    "        )['default']['trendingSearchesDays'][0]['trendingSearches']\n",
    "        result_df = pd.DataFrame()\n",
    "        # parse the returned json\n",
    "        sub_df = pd.DataFrame()\n",
    "        for trend in req_json:\n",
    "            sub_df = sub_df.append(trend['title'], ignore_index=True)\n",
    "        result_df = pd.concat([result_df, sub_df])\n",
    "        return result_df.iloc[:, -1]\n",
    "\n",
    "    def top_charts(self, date, hl='en-US', tz=300, geo='GLOBAL'):\n",
    "        \"\"\"Request data from Google's Top Charts section and return a dataframe\"\"\"\n",
    "        # create the payload\n",
    "        chart_payload = {'hl': hl, 'tz': tz, 'date': date, 'geo': geo,\n",
    "                         'isMobile': False}\n",
    "\n",
    "        # make the request and parse the returned json\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.TOP_CHARTS_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "            params=chart_payload,\n",
    "        )['topCharts'][0]['listItems']\n",
    "        df = pd.DataFrame(req_json)\n",
    "        return df\n",
    "\n",
    "    def suggestions(self, keyword):\n",
    "        \"\"\"Request data from Google's Keyword Suggestion dropdown and return a dictionary\"\"\"\n",
    "\n",
    "        # make the request\n",
    "        kw_param = quote(keyword)\n",
    "        parameters = {'hl': self.hl}\n",
    "\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.SUGGESTIONS_URL + kw_param,\n",
    "            params=parameters,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "        )['default']['topics']\n",
    "        return req_json\n",
    "\n",
    "    def categories(self):\n",
    "        \"\"\"Request available categories data from Google's API and return a dictionary\"\"\"\n",
    "\n",
    "        params = {'hl': self.hl}\n",
    "\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.CATEGORIES_URL,\n",
    "            params=params,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "        )\n",
    "        return req_json\n",
    "\n",
    "    def get_historical_interest(self, keywords, year_start=2018, month_start=1,\n",
    "                                day_start=1, hour_start=0, year_end=2018,\n",
    "                                month_end=2, day_end=1, hour_end=0, cat=0,\n",
    "                                geo='', gprop='', sleep=0):\n",
    "        \"\"\"Gets historical hourly data for interest by chunking requests to 1 week at a time (which is what Google allows)\"\"\"\n",
    "\n",
    "        # construct datetime obejcts - raises ValueError if invalid parameters\n",
    "        initial_start_date = start_date = datetime(year_start, month_start,\n",
    "                                                   day_start, hour_start)\n",
    "        end_date = datetime(year_end, month_end, day_end, hour_end)\n",
    "\n",
    "        # the timeframe has to be in 1 week intervals or Google will reject it\n",
    "        delta = timedelta(days=7)\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        date_iterator = start_date\n",
    "        date_iterator += delta\n",
    "\n",
    "        while True:\n",
    "            # format date to comply with API call\n",
    "\n",
    "            start_date_str = start_date.strftime('%Y-%m-%dT%H')\n",
    "            date_iterator_str = date_iterator.strftime('%Y-%m-%dT%H')\n",
    "\n",
    "            tf = start_date_str + ' ' + date_iterator_str\n",
    "\n",
    "            try:\n",
    "                self.build_payload(keywords, cat, tf, geo, gprop)\n",
    "                week_df = self.interest_over_time()\n",
    "                df = pd.concat([df, week_df])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "            start_date += delta\n",
    "            date_iterator += delta\n",
    "\n",
    "            if (date_iterator > end_date):\n",
    "                # Run for 7 more days to get remaining data that would have been truncated if we stopped now\n",
    "                # This is needed because google requires 7 days yet we may end up with a week result less than a full week\n",
    "                start_date_str = start_date.strftime('%Y-%m-%dT%H')\n",
    "                date_iterator_str = date_iterator.strftime('%Y-%m-%dT%H')\n",
    "\n",
    "                tf = start_date_str + ' ' + date_iterator_str\n",
    "\n",
    "                try:\n",
    "                    self.build_payload(keywords, cat, tf, geo, gprop)\n",
    "                    week_df = self.interest_over_time()\n",
    "                    df = pd.concat([df, week_df])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    pass\n",
    "                break\n",
    "\n",
    "            # just in case you are rate-limited by Google. Recommended is 60 if you are.\n",
    "            if sleep > 0:\n",
    "                time.sleep(sleep)\n",
    "\n",
    "        # Return the dataframe with results from our timeframe\n",
    "        return df.loc[initial_start_date:end_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC</th>\n",
       "      <th>Blockchain</th>\n",
       "      <th>Bitcoin</th>\n",
       "      <th>isPartial</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-31 20:00:00</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-31 21:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-31 22:00:00</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-31 23:00:00</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>749 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BTC  Blockchain  Bitcoin  isPartial\n",
       "date                                                    \n",
       "2018-01-01 00:00:00   14           3       73      False\n",
       "2018-01-01 01:00:00   13           3       72      False\n",
       "2018-01-01 02:00:00   18           4       69      False\n",
       "2018-01-01 03:00:00   18           5       67      False\n",
       "2018-01-01 04:00:00   18           5       71      False\n",
       "...                  ...         ...      ...        ...\n",
       "2018-01-31 20:00:00    7           4       38      False\n",
       "2018-01-31 21:00:00    6           5       39      False\n",
       "2018-01-31 22:00:00    8           3       41      False\n",
       "2018-01-31 23:00:00    9           5       43      False\n",
       "2018-02-01 00:00:00    7           4       43      False\n",
       "\n",
       "[749 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytrends = GTrends(hl='fr-FR', tz=360) \n",
    "\n",
    "kewords_list = [\"BTC\",\"Blockchain\",\"Bitcoin\"] # list of keywords to get data \n",
    "\n",
    "gtrends_data = pytrends.get_historical_interest(kewords_list,\n",
    "                                        # year_start=btc_df.index[0].year,\n",
    "                                        # month_start=btc_df.index[0].month,\n",
    "                                        # day_start=btc_df.index[0].day,\n",
    "                                        # hour_start=btc_df.index[0].hour,\n",
    "                                        # year_end=btc_df.index[-1].year,\n",
    "                                        # month_end=btc_df.index[-1].month,\n",
    "                                        # day_end=btc_df.index[-1].day,\n",
    "                                        # hour_end=btc_df.index[-1].hour,\n",
    "                                        cat=0, sleep=2,)\n",
    "\n",
    "gtrends_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTimestampToDf(df)->pd.DataFrame:\n",
    "    \"\"\"add timestamp to dataframe as column\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The Dataframe we want to add timestamp as col\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The Dataframe with the new column\n",
    "    \"\"\"\n",
    "    df['Timestamp'] = [round(datetime.timestamp(df.index[ind])) for ind in range(len(df.index))]\n",
    "    df['Timestamp'] = df['Timestamp'].astype(int)\n",
    "    return df\n",
    "gtrends_data = addTimestampToDf(gtrends_data)\n",
    "\n",
    "gtrends_data = gtrends_data.drop_duplicates(subset=['Timestamp'],keep='first')\n",
    "print(len(gtrends_data))\n",
    "gtrends_data['BTC'] = gtrends_data.apply(lambda x: x['BTC']+x['Bitcoin']+x['Blockchain'], axis=1)\n",
    "gtrends_data.drop(columns=['Bitcoin','isPartial','Blockchain'], inplace=True)\n",
    "gtrends_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a8ac14bf36a38d23b084974fa7edcc657a6812d6ea49c634ed3c7e142f857e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
